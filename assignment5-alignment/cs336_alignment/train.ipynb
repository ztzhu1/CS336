{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-09 02:19:14 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "project_dir = Path(os.path.abspath('')).parent\n",
    "sys.path.insert(0, project_dir.as_posix())\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import  pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from cs336_alignment import  train_llm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = train_llm.load_model(device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mztzhu1\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/assignment5-alignment/cs336_alignment/wandb/run-20251105_144319-8oqsgkzx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx' target=\"_blank\">MATH_100</a></strong> to <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fee3ba20fe4b1eb9148d22de36af7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2, 1/24], loss: 0.6364, token_entropy: 0.5592\n",
      "[1/2, 2/24], loss: 0.5823, token_entropy: 0.5860\n",
      "[1/2, 3/24], loss: 0.5400, token_entropy: 0.5778\n",
      "[1/2, 4/24], loss: 0.3649, token_entropy: 0.2796\n",
      "[1/2, 5/24], loss: 0.3937, token_entropy: 0.3809\n",
      "[1/2, 6/24], loss: 0.4303, token_entropy: 0.3602\n",
      "[1/2, 7/24], loss: 0.3572, token_entropy: 0.3301\n",
      "[1/2, 8/24], loss: 0.4178, token_entropy: 0.3572\n",
      "[1/2, 9/24], loss: 0.4333, token_entropy: 0.3701\n",
      "[1/2, 10/24], loss: 0.4496, token_entropy: 0.3969\n",
      "[1/2, 11/24], loss: 0.4327, token_entropy: 0.3465\n",
      "[1/2, 12/24], loss: 0.4501, token_entropy: 0.3917\n",
      "[2/2, 13/24], loss: 0.1490, token_entropy: 0.2787\n",
      "[2/2, 14/24], loss: 0.1464, token_entropy: 0.2636\n",
      "[2/2, 15/24], loss: 0.1467, token_entropy: 0.2303\n",
      "[2/2, 16/24], loss: 0.2039, token_entropy: 0.2734\n",
      "[2/2, 17/24], loss: 0.1493, token_entropy: 0.1984\n",
      "[2/2, 18/24], loss: 0.1607, token_entropy: 0.2045\n",
      "[2/2, 19/24], loss: 0.1483, token_entropy: 0.1847\n",
      "[2/2, 20/24], loss: 0.1164, token_entropy: 0.1467\n",
      "[2/2, 21/24], loss: 0.1352, token_entropy: 0.1438\n",
      "[2/2, 22/24], loss: 0.1760, token_entropy: 0.1820\n",
      "[2/2, 23/24], loss: 0.2035, token_entropy: 0.1781\n",
      "[2/2, 24/24], loss: 0.1164, token_entropy: 0.1729\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁████████████</td></tr><tr><td>train/loss</td><td>█▇▇▄▅▅▄▅▅▅▅▅▁▁▁▂▁▂▁▁▁▂▂▁</td></tr><tr><td>train/token_entropy</td><td>███▃▅▄▄▄▅▅▄▅▃▃▂▃▂▂▂▁▁▂▂▁</td></tr><tr><td>train_step</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_step</td><td>24</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MATH_100</strong> at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx</a><br> View project at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251105_144319-8oqsgkzx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_llm.train(model, tokenizer, log_name='Qwen2.5-Math-1.5B-MATH', max_samples=128,\n",
    "                per_device_train_batch_size=1, gradient_accumulation_steps=8, num_train_epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mztzhu1\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/assignment5-alignment/cs336_alignment/wandb/run-20251106_152341-uerwbrkf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf' target=\"_blank\">Qwen2.5-Math-1.5B-MATH</a></strong> to <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n",
      "  1%|▏         | 1/80 [00:03<04:53,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 1/80], loss: 0.6147, token_entropy: 0.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [00:08<05:45,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 2/80], loss: 0.5213, token_entropy: 0.4425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/80 [00:13<05:41,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 3/80], loss: 0.4693, token_entropy: 0.6518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/80 [00:17<05:36,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 4/80], loss: 0.4847, token_entropy: 0.4404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/80 [00:21<05:32,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 5/80], loss: 0.4246, token_entropy: 0.4262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:26<05:18,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 6/80], loss: 0.3908, token_entropy: 0.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/80 [00:30<05:28,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 7/80], loss: 0.4351, token_entropy: 0.3663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/80 [00:34<05:12,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 8/80], loss: 0.4140, token_entropy: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/80 [00:39<05:06,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 9/80], loss: 0.3869, token_entropy: 0.3553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [00:43<04:54,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 10/80], loss: 0.3692, token_entropy: 0.3392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [00:47<04:43,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 11/80], loss: 0.4189, token_entropy: 0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [00:51<04:48,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 12/80], loss: 0.4178, token_entropy: 0.3971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [00:56<04:51,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 13/80], loss: 0.3637, token_entropy: 0.3466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/80 [01:00<04:55,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 14/80], loss: 0.4254, token_entropy: 0.4052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/80 [01:05<04:44,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 15/80], loss: 0.4195, token_entropy: 0.3988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 16/80 [01:14<06:25,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 16/80], loss: 0.4243, token_entropy: 0.4094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 17/80 [01:19<05:47,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 17/80], loss: 0.1978, token_entropy: 0.3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 18/80 [01:23<05:20,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 18/80], loss: 0.1721, token_entropy: 0.2941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/80 [01:27<04:52,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 19/80], loss: 0.1554, token_entropy: 0.2348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/80 [01:32<04:45,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 20/80], loss: 0.1716, token_entropy: 0.2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 21/80 [01:36<04:27,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 21/80], loss: 0.1520, token_entropy: 0.1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [01:40<04:21,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 22/80], loss: 0.1420, token_entropy: 0.1307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [01:44<04:08,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 23/80], loss: 0.1477, token_entropy: 0.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/80 [01:49<04:07,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 24/80], loss: 0.1564, token_entropy: 0.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 25/80 [01:53<04:06,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 25/80], loss: 0.1485, token_entropy: 0.1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 26/80 [01:57<03:54,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 26/80], loss: 0.1238, token_entropy: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/80 [02:02<03:55,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 27/80], loss: 0.1544, token_entropy: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/80 [02:06<03:47,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 28/80], loss: 0.1461, token_entropy: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 29/80 [02:11<03:51,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 29/80], loss: 0.1359, token_entropy: 0.1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/80 [02:16<03:45,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 30/80], loss: 0.1410, token_entropy: 0.1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/80 [02:20<03:37,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 31/80], loss: 0.1694, token_entropy: 0.1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 32/80 [02:30<04:49,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 32/80], loss: 0.1462, token_entropy: 0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 33/80 [02:34<04:21,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 33/80], loss: 0.0685, token_entropy: 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 34/80 [02:39<04:05,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 34/80], loss: 0.0637, token_entropy: 0.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/80 [02:43<03:43,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 35/80], loss: 0.0580, token_entropy: 0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 36/80 [02:47<03:28,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 36/80], loss: 0.0533, token_entropy: 0.0988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 37/80 [02:52<03:19,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 37/80], loss: 0.0553, token_entropy: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/80 [02:56<03:10,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 38/80], loss: 0.0489, token_entropy: 0.0849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/80 [03:00<03:04,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 39/80], loss: 0.0485, token_entropy: 0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 40/80 [03:05<02:58,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 40/80], loss: 0.0501, token_entropy: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 41/80 [03:09<02:56,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 41/80], loss: 0.0482, token_entropy: 0.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [03:14<02:46,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 42/80], loss: 0.0455, token_entropy: 0.0648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/80 [03:18<02:42,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 43/80], loss: 0.0671, token_entropy: 0.0616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 44/80 [03:22<02:35,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 44/80], loss: 0.0629, token_entropy: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 45/80 [03:26<02:28,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 45/80], loss: 0.0502, token_entropy: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 46/80 [03:31<02:25,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 46/80], loss: 0.0540, token_entropy: 0.0535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 47/80 [03:35<02:22,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 47/80], loss: 0.0339, token_entropy: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 48/80 [03:45<03:09,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 48/80], loss: 0.0692, token_entropy: 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 49/80 [03:49<02:51,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 49/80], loss: 0.0197, token_entropy: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 50/80 [03:53<02:33,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 50/80], loss: 0.0253, token_entropy: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 51/80 [03:58<02:25,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 51/80], loss: 0.0176, token_entropy: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 52/80 [04:02<02:13,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 52/80], loss: 0.0140, token_entropy: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 53/80 [04:06<02:02,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 53/80], loss: 0.0111, token_entropy: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/80 [04:11<01:55,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 54/80], loss: 0.0123, token_entropy: 0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 55/80 [04:15<01:49,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 55/80], loss: 0.0134, token_entropy: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 56/80 [04:19<01:45,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 56/80], loss: 0.0102, token_entropy: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 57/80 [04:24<01:42,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 57/80], loss: 0.0158, token_entropy: 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 58/80 [04:28<01:38,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 58/80], loss: 0.0075, token_entropy: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 59/80 [04:33<01:32,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 59/80], loss: 0.0110, token_entropy: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 60/80 [04:37<01:26,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 60/80], loss: 0.0169, token_entropy: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 61/80 [04:41<01:23,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 61/80], loss: 0.0114, token_entropy: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [04:46<01:19,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 62/80], loss: 0.0122, token_entropy: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 63/80 [04:50<01:15,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 63/80], loss: 0.0132, token_entropy: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 64/80 [05:00<01:35,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 64/80], loss: 0.0082, token_entropy: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 65/80 [05:04<01:21,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 65/80], loss: 0.0039, token_entropy: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 66/80 [05:08<01:11,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 66/80], loss: 0.0060, token_entropy: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 67/80 [05:13<01:03,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 67/80], loss: 0.0030, token_entropy: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 68/80 [05:17<00:55,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 68/80], loss: 0.0074, token_entropy: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 69/80 [05:21<00:48,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 69/80], loss: 0.0019, token_entropy: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 70/80 [05:25<00:43,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 70/80], loss: 0.0031, token_entropy: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 71/80 [05:29<00:38,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 71/80], loss: 0.0038, token_entropy: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 72/80 [05:33<00:34,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 72/80], loss: 0.0095, token_entropy: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 73/80 [05:38<00:30,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 73/80], loss: 0.0026, token_entropy: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 74/80 [05:43<00:27,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 74/80], loss: 0.0035, token_entropy: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 75/80 [05:47<00:22,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 75/80], loss: 0.0037, token_entropy: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 76/80 [05:51<00:17,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 76/80], loss: 0.0030, token_entropy: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 77/80 [05:56<00:13,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 77/80], loss: 0.0033, token_entropy: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 78/80 [06:01<00:09,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 78/80], loss: 0.0038, token_entropy: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 79/80 [06:05<00:04,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 79/80], loss: 0.0026, token_entropy: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [06:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 80/80], loss: 0.0036, token_entropy: 0.0058\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆███████</td></tr><tr><td>train/loss</td><td>█▇▆▅▅▅▆▆▃▃▃▃▃▃▃▃▂▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/token_entropy</td><td>███▇▇▆▇▆▄▃▃▃▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_step</td><td>80</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Qwen2.5-Math-1.5B-MATH</strong> at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf</a><br> View project at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251106_152341-uerwbrkf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_llm.train(model, tokenizer, log_name='Qwen2.5-Math-1.5B-MATH', max_samples=256,\n",
    "                per_device_train_batch_size=1, gradient_accumulation_steps=16, num_train_epochs=5, eval_per_epoch=True, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_llm.evaluate_dataset(model, tokenizer, batch_size=32, save_path='Qwen2.5-Math-1.5B-MATH-sample256-epoch5-step80.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mztzhu1\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/assignment5-alignment/cs336_alignment/wandb/run-20251108_134551-o316vxd0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/o316vxd0' target=\"_blank\">Qwen2.5-Math-1.5B-MATH-amp</a></strong> to <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/o316vxd0' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/o316vxd0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n",
      "  1%|▏         | 1/80 [00:02<02:45,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 1/80], loss: 0.5669, token_entropy: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [00:04<02:36,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 2/80], loss: 0.5315, token_entropy: 0.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/80 [00:05<02:31,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 3/80], loss: 0.5242, token_entropy: 0.4323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/80 [00:08<02:33,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 4/80], loss: 0.4760, token_entropy: 0.3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/80 [00:10<02:32,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 5/80], loss: 0.5097, token_entropy: 0.5154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:12<02:29,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 6/80], loss: 0.4807, token_entropy: 0.5729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/80 [00:14<02:26,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 7/80], loss: 0.3706, token_entropy: 0.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/80 [00:16<02:25,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 8/80], loss: 0.4023, token_entropy: 0.3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/80 [00:18<02:21,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 9/80], loss: 0.4168, token_entropy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [00:20<02:18,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 10/80], loss: 0.4151, token_entropy: 0.3260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [00:21<02:15,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 11/80], loss: 0.3625, token_entropy: 0.3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [00:24<02:17,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 12/80], loss: 0.4718, token_entropy: 0.3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [00:26<02:15,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 13/80], loss: 0.4228, token_entropy: 0.3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/80 [00:28<02:15,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 14/80], loss: 0.4279, token_entropy: 0.3995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/80 [00:30<02:14,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 15/80], loss: 0.3556, token_entropy: 0.3493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 16/80 [00:32<02:10,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5, 16/80], loss: 0.4005, token_entropy: 0.3947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 17/80 [00:34<02:09,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 17/80], loss: 0.2391, token_entropy: 0.3418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 18/80 [00:36<02:07,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 18/80], loss: 0.1807, token_entropy: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/80 [00:38<02:05,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 19/80], loss: 0.1717, token_entropy: 0.2759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/80 [00:40<02:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 20/80], loss: 0.1895, token_entropy: 0.2787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 21/80 [00:42<02:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 21/80], loss: 0.1765, token_entropy: 0.2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:44<01:58,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 22/80], loss: 0.2235, token_entropy: 0.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [00:46<01:55,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 23/80], loss: 0.1303, token_entropy: 0.1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/80 [00:48<01:54,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 24/80], loss: 0.1851, token_entropy: 0.1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 25/80 [00:50<01:51,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 25/80], loss: 0.1336, token_entropy: 0.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 26/80 [00:52<01:48,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 26/80], loss: 0.1281, token_entropy: 0.1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/80 [00:54<01:46,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 27/80], loss: 0.1516, token_entropy: 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/80 [00:56<01:45,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 28/80], loss: 0.1406, token_entropy: 0.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 29/80 [00:58<01:42,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 29/80], loss: 0.1279, token_entropy: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/80 [01:00<01:39,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 30/80], loss: 0.1691, token_entropy: 0.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/80 [01:02<01:37,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 31/80], loss: 0.1415, token_entropy: 0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 32/80 [01:04<01:35,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5, 32/80], loss: 0.1498, token_entropy: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 33/80 [01:06<01:33,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 33/80], loss: 0.0563, token_entropy: 0.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 34/80 [01:08<01:31,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 34/80], loss: 0.0539, token_entropy: 0.0921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/80 [01:10<01:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 35/80], loss: 0.0658, token_entropy: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 36/80 [01:12<01:26,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 36/80], loss: 0.0568, token_entropy: 0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 37/80 [01:14<01:26,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 37/80], loss: 0.0566, token_entropy: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/80 [01:16<01:22,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 38/80], loss: 0.0473, token_entropy: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/80 [01:18<01:21,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 39/80], loss: 0.0553, token_entropy: 0.0766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 40/80 [01:20<01:19,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 40/80], loss: 0.0394, token_entropy: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 41/80 [01:22<01:18,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 41/80], loss: 0.0596, token_entropy: 0.0734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [01:24<01:16,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 42/80], loss: 0.0352, token_entropy: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/80 [01:26<01:15,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 43/80], loss: 0.0478, token_entropy: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 44/80 [01:28<01:14,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 44/80], loss: 0.0598, token_entropy: 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 45/80 [01:30<01:12,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 45/80], loss: 0.0498, token_entropy: 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 46/80 [01:33<01:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 46/80], loss: 0.0588, token_entropy: 0.0570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 47/80 [01:35<01:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 47/80], loss: 0.0500, token_entropy: 0.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 48/80 [01:37<01:05,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5, 48/80], loss: 0.0490, token_entropy: 0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 49/80 [01:39<01:03,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 49/80], loss: 0.0144, token_entropy: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 50/80 [01:41<01:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 50/80], loss: 0.0110, token_entropy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 51/80 [01:43<00:59,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 51/80], loss: 0.0164, token_entropy: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 52/80 [01:45<00:57,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 52/80], loss: 0.0117, token_entropy: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 53/80 [01:47<00:54,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 53/80], loss: 0.0098, token_entropy: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/80 [01:49<00:52,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 54/80], loss: 0.0092, token_entropy: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 55/80 [01:51<00:50,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 55/80], loss: 0.0145, token_entropy: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 56/80 [01:53<00:49,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 56/80], loss: 0.0103, token_entropy: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 57/80 [01:55<00:46,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 57/80], loss: 0.0109, token_entropy: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 58/80 [01:57<00:44,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 58/80], loss: 0.0123, token_entropy: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 59/80 [01:59<00:42,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 59/80], loss: 0.0177, token_entropy: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 60/80 [02:01<00:40,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 60/80], loss: 0.0132, token_entropy: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 61/80 [02:03<00:38,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 61/80], loss: 0.0119, token_entropy: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [02:05<00:36,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 62/80], loss: 0.0132, token_entropy: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 63/80 [02:07<00:34,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 63/80], loss: 0.0105, token_entropy: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 64/80 [02:09<00:32,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5, 64/80], loss: 0.0176, token_entropy: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 65/80 [02:11<00:31,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 65/80], loss: 0.0051, token_entropy: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 66/80 [02:13<00:28,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 66/80], loss: 0.0048, token_entropy: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 67/80 [02:15<00:26,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 67/80], loss: 0.0039, token_entropy: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 68/80 [02:17<00:24,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 68/80], loss: 0.0019, token_entropy: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 69/80 [02:19<00:22,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 69/80], loss: 0.0061, token_entropy: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 70/80 [02:21<00:20,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 70/80], loss: 0.0032, token_entropy: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 71/80 [02:23<00:18,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 71/80], loss: 0.0023, token_entropy: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 72/80 [02:25<00:15,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 72/80], loss: 0.0027, token_entropy: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 73/80 [02:27<00:13,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 73/80], loss: 0.0032, token_entropy: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 74/80 [02:29<00:12,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 74/80], loss: 0.0056, token_entropy: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 75/80 [02:31<00:10,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 75/80], loss: 0.0032, token_entropy: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 76/80 [02:33<00:08,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 76/80], loss: 0.0028, token_entropy: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 77/80 [02:36<00:06,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 77/80], loss: 0.0032, token_entropy: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 78/80 [02:38<00:04,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 78/80], loss: 0.0031, token_entropy: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 79/80 [02:40<00:02,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 79/80], loss: 0.0052, token_entropy: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [02:42<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5, 80/80], loss: 0.0020, token_entropy: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆█████████</td></tr><tr><td>train/loss</td><td>██▆▆▆▇▆▆▃▃▄▃▃▃▃▃▃▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/time</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train/token_entropy</td><td>▇█▆▆▅▆▆▆▅▆▄▄▄▂▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_step</td><td>80</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Qwen2.5-Math-1.5B-MATH-amp</strong> at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/o316vxd0' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/o316vxd0</a><br> View project at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251108_134551-o316vxd0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_llm.train(model, tokenizer, log_name='Qwen2.5-Math-1.5B-MATH-amp', max_samples=256,\n",
    "                per_device_train_batch_size=1, gradient_accumulation_steps=16, num_train_epochs=5, eval_per_epoch=False, save=True, use_amp=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [01:55<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/assignment5-alignment/cs336_alignment/train_llm.py:633\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, tokenizer, lr, num_train_epochs, per_device_train_batch_size, gradient_accumulation_steps, eval_per_epoch, max_steps, max_samples, sft_data, log_name, save, save_per_epoch, use_amp)\u001b[39m\n\u001b[32m    629\u001b[39m response_mask = input_data.pop(\u001b[33m\"\u001b[39m\u001b[33mresponse_mask\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autocast(\n\u001b[32m    631\u001b[39m     device_type=\u001b[38;5;28mstr\u001b[39m(device), dtype=torch.float16, enabled=use_amp\n\u001b[32m    632\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     result = \u001b[43mget_response_log_probs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_entropy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m     log_probs = result[\u001b[33m\"\u001b[39m\u001b[33mlog_probs\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    640\u001b[39m     normalize_constant = response_mask.sum(-\u001b[32m1\u001b[39m).max()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:736\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    733\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    738\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:1495\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1489\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1490\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1491\u001b[39m             )\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1497\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:1272\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1270\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1272\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1275\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:629\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    626\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:1111\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package)\u001b[39m\n\u001b[32m   1109\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1110\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1111\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1113\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m   1115\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1120\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m   1121\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m   1122\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_utils_internal.py:97\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m    100\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:793\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    787\u001b[39m     stack.enter_context(\n\u001b[32m    788\u001b[39m         torch._dynamo.callback_handler.install_callbacks(\n\u001b[32m    789\u001b[39m             CallbackTrigger.DYNAMO, \u001b[38;5;28mstr\u001b[39m(CompileContext.current_compile_id())\n\u001b[32m    790\u001b[39m         )\n\u001b[32m    791\u001b[39m     )\n\u001b[32m    792\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    796\u001b[39m     ConvertFrameReturn()\n\u001b[32m    797\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:832\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m    830\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcompile_attempt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    831\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m         out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py:1424\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1421\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1422\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1424\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:267\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    265\u001b[39m exit_stack.enter_context(torch_function_mode_stack_state_mgr)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    269\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:753\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    751\u001b[39m     tracer.output.mark_bytecode_tracing_start()\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    755\u001b[39m     speculation_log.clear()  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3497\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3496\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3497\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:1363\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28mself\u001b[39m.start_point = \u001b[38;5;28mself\u001b[39m.instruction_pointer\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1364\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:1267\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1264\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1267\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m   1269\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3672\u001b[39m, in \u001b[36mInstructionTranslator.RETURN_VALUE\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3671\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mRETURN_VALUE\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m3672\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3653\u001b[39m, in \u001b[36mInstructionTranslator._return\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3648\u001b[39m _step_logger()(\n\u001b[32m   3649\u001b[39m     logging.INFO,\n\u001b[32m   3650\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.f_code.co_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst.opname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3651\u001b[39m )\n\u001b[32m   3652\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m triggered compile\u001b[39m\u001b[33m\"\u001b[39m, inst.opname)\n\u001b[32m-> \u001b[39m\u001b[32m3653\u001b[39m all_stack_locals_metadata = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3656\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreturn_value\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   3657\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3658\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3659\u001b[39m \u001b[38;5;66;03m# check that our stack/locals meta are correct:\u001b[39;00m\n\u001b[32m   3660\u001b[39m \u001b[38;5;66;03m# we should only be tracing 1 frame, and there should not be any NULLs on the stack\u001b[39;00m\n\u001b[32m   3661\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_stack_locals_metadata) == \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1422\u001b[39m, in \u001b[36mOutputGraph.compile_subgraph\u001b[39m\u001b[34m(self, tx, reason, partial_convert, stack_pops)\u001b[39m\n\u001b[32m   1419\u001b[39m output = []\n\u001b[32m   1420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m count_calls(\u001b[38;5;28mself\u001b[39m.graph) != \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2.graph_outputs) != \u001b[32m0\u001b[39m:\n\u001b[32m   1421\u001b[39m     output.extend(\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgraph_output_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1423\u001b[39m     )\n\u001b[32m   1425\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2.graph_outputs) != \u001b[32m0\u001b[39m:\n\u001b[32m   1426\u001b[39m         output.append(pass2.create_store(graph_output_var))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1696\u001b[39m, in \u001b[36mOutputGraph.compile_and_call_fx_graph\u001b[39m\u001b[34m(self, tx, rv, root)\u001b[39m\n\u001b[32m   1693\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracing_context.fake_mode = backend_fake_mode\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.restore_global_state():\n\u001b[32m-> \u001b[39m\u001b[32m1696\u001b[39m     compiled_fn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_graph_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LazyGraphModule\n\u001b[32m   1700\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, _LazyGraphModule) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1701\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(compiled_fn, \u001b[33m\"\u001b[39m\u001b[33m__self__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), _LazyGraphModule)\n\u001b[32m   1702\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m compiled_fn.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m_lazy_forward\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1706\u001b[39m     \u001b[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001b[39;00m\n\u001b[32m   1707\u001b[39m     \u001b[38;5;66;03m# optimize a _LazyGraphModule.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1811\u001b[39m, in \u001b[36mOutputGraph.call_user_compiler\u001b[39m\u001b[34m(self, gm, example_inputs)\u001b[39m\n\u001b[32m   1800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_user_compiler\u001b[39m(\n\u001b[32m   1801\u001b[39m     \u001b[38;5;28mself\u001b[39m, gm: fx.GraphModule, example_inputs: \u001b[38;5;28mlist\u001b[39m[Tensor]\n\u001b[32m   1802\u001b[39m ) -> CompiledFn:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   1804\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1805\u001b[39m         phase_name=\u001b[33m\"\u001b[39m\u001b[33mbackend_compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1809\u001b[39m         dynamo_compile_column_us=\u001b[33m\"\u001b[39m\u001b[33maot_autograd_cumulative_compile_time_us\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1811\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1846\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm, example_inputs)\u001b[39m\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.verify_correctness:\n\u001b[32m   1845\u001b[39m     compiler_fn = WrapperBackend(compiler_fn)\n\u001b[32m-> \u001b[39m\u001b[32m1846\u001b[39m compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1847\u001b[39m _step_logger()(logging.INFO, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1848\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(compiled_fn), \u001b[33m\"\u001b[39m\u001b[33mcompiler_fn did not return callable\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/repro/after_dynamo.py:150\u001b[39m, in \u001b[36mWrapBackendDebug.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     compiled_gm = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/__init__.py:2380\u001b[39m, in \u001b[36m_TorchCompileInductorWrapper.__call__\u001b[39m\u001b[34m(self, model_, inputs_)\u001b[39m\n\u001b[32m   2377\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_, inputs_):\n\u001b[32m   2378\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompile_fx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[32m-> \u001b[39m\u001b[32m2380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:2418\u001b[39m, in \u001b[36mcompile_fx\u001b[39m\u001b[34m(model_, example_inputs_, inner_compile, config_patches, decompositions, ignore_shape_env)\u001b[39m\n\u001b[32m   2411\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   2412\u001b[39m     V.set_fake_mode(fake_mode),\n\u001b[32m   2413\u001b[39m     torch._guards.tracing(tracing_context),\n\u001b[32m   2414\u001b[39m     compiled_autograd._disable(),\n\u001b[32m   2415\u001b[39m     functorch_config.patch(unlift_effect_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m   2416\u001b[39m ):\n\u001b[32m   2417\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2418\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2419\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2420\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2421\u001b[39m \u001b[43m            \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2422\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2423\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2424\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2425\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2426\u001b[39m \u001b[43m            \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2427\u001b[39m \u001b[43m            \u001b[49m\u001b[43mignore_shape_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_shape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2428\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ShortenTraceback \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2430\u001b[39m         \u001b[38;5;66;03m# We will also shorten the traceback inside dynamo.\u001b[39;00m\n\u001b[32m   2431\u001b[39m         \u001b[38;5;66;03m# This is only useful if inductor is called directly with an FX graph.\u001b[39;00m\n\u001b[32m   2432\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e.remove_dynamo_frames() \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/backends/common.py:109\u001b[39m, in \u001b[36mAotAutograd.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# NB: NOT cloned!\u001b[39;00m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m         cg = \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m         counters[\u001b[33m\"\u001b[39m\u001b[33maot_autograd\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m disable(cg, reason=\u001b[33m\"\u001b[39m\u001b[33mdo not trace AOT-compiled graph\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:1199\u001b[39m, in \u001b[36maot_module_simplified\u001b[39m\u001b[34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs, boxed_forward_device_index, ignore_shape_env)\u001b[39m\n\u001b[32m   1197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local \u001b[38;5;129;01mor\u001b[39;00m remote:\n\u001b[32m   1198\u001b[39m     set_feature_use(\u001b[33m\"\u001b[39m\u001b[33maot_autograd_remote_cache\u001b[39m\u001b[33m\"\u001b[39m, remote)\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m     compiled_fn = \u001b[43mAOTAutogradCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdispatch_and_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mremote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1210\u001b[39m     compiled_fn = dispatch_and_compile()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1140\u001b[39m, in \u001b[36mAOTAutogradCache.load\u001b[39m\u001b[34m(dispatch_and_compile, mod, args, aot_config, cudagraphs, boxed_forward_device_index, local, remote)\u001b[39m\n\u001b[32m   1134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1135\u001b[39m         aot_config.cache_info = AOTAutogradCacheInfo(\n\u001b[32m   1136\u001b[39m             cache_key,\n\u001b[32m   1137\u001b[39m             time.time_ns(),\n\u001b[32m   1138\u001b[39m             forward_symints=symints,\n\u001b[32m   1139\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m     compiled_fn = \u001b[43mdispatch_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1142\u001b[39m cache_info.update(\n\u001b[32m   1143\u001b[39m     {\n\u001b[32m   1144\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mkey\u001b[39m\u001b[33m\"\u001b[39m: cache_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1147\u001b[39m     }\n\u001b[32m   1148\u001b[39m )\n\u001b[32m   1149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chromium_event_log_active():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:1184\u001b[39m, in \u001b[36maot_module_simplified.<locals>.dispatch_and_compile\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1182\u001b[39m functional_call = create_functional_call(mod, params_spec, params_len)\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd._disable():\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     compiled_fn, _ = \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:576\u001b[39m, in \u001b[36mcreate_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_aot_dispatcher_function\u001b[39m(\n\u001b[32m    569\u001b[39m     flat_fn,\n\u001b[32m    570\u001b[39m     fake_flat_args: FakifiedFlatArgs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m     shape_env: Optional[ShapeEnv],\n\u001b[32m    574\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Callable, ViewAndMutationMeta]:\n\u001b[32m    575\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcreate_aot_dispatcher_function\u001b[39m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m            \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_env\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:836\u001b[39m, in \u001b[36m_create_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    832\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m aot_dispatch_base\n\u001b[32m    834\u001b[39m compiler_fn = choose_dispatcher(needs_autograd, aot_config)\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m compiled_fn, fw_metadata = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_dup_fake_script_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn, fw_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1700\u001b[39m, in \u001b[36maot_dispatch_autograd\u001b[39m\u001b[34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[39m\n\u001b[32m   1695\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch._subclasses.fake_tensor.unset_fake_temporarily():\n\u001b[32m   1696\u001b[39m         \u001b[38;5;66;03m# If bw_module contains lifted constants, they will be real tensors stored as\u001b[39;00m\n\u001b[32m   1697\u001b[39m         \u001b[38;5;66;03m# GraphModule. Deepcopying tensors under fake mode is not supported and will\u001b[39;00m\n\u001b[32m   1698\u001b[39m         \u001b[38;5;66;03m# raise when attempting to set storage.\u001b[39;00m\n\u001b[32m   1699\u001b[39m         bw_module_copy = copy.deepcopy(bw_module)\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     compiled_bw_func = \u001b[43maot_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbw_module_copy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplaceholder_list\u001b[49m\n\u001b[32m   1702\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m bw_module_copy\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:483\u001b[39m, in \u001b[36mSerializableAOTDispatchCompiler.__call__\u001b[39m\u001b[34m(self, gm, example_inputs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    479\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    480\u001b[39m     gm: torch.fx.GraphModule,\n\u001b[32m    481\u001b[39m     example_inputs: Sequence[InputType],\n\u001b[32m    482\u001b[39m ) -> OutputCode:\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/backends/common.py:76\u001b[39m, in \u001b[36mAotAutograd.__call__.<locals>.wrap_bw_compiler.<locals>._wrapped_bw_compiler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_bw_compiler\u001b[39m(*args, **kwargs):\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# Note [Wrapping bw_compiler in disable]\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# The two disables here:\u001b[39;00m\n\u001b[32m     73\u001b[39m     \u001b[38;5;66;03m# - stop TorchDynamo from trying to compile the bw_compiler function itself\u001b[39;00m\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# - stop TorchDynamo from trying to compile our the generated backwards pass bw_compiler produces\u001b[39;00m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disable(\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbw_compiler_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreason\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdo not trace backward compiler function\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     79\u001b[39m         reason=\u001b[33m\"\u001b[39m\u001b[33mdo not trace generated backwards pass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     80\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:929\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    927\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    931\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_utils_internal.py:97\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m    100\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:2335\u001b[39m, in \u001b[36mcompile_fx.<locals>.bw_compiler\u001b[39m\u001b[34m(gm, example_inputs)\u001b[39m\n\u001b[32m   2329\u001b[39m fixed = count_tangents(gm)\n\u001b[32m   2330\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   2331\u001b[39m     config.patch(get_cpp_wrapper_config())\n\u001b[32m   2332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.cpp_wrapper\n\u001b[32m   2333\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext()\n\u001b[32m   2334\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m2335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2340\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_backward\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:745\u001b[39m, in \u001b[36mcompile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    740\u001b[39m stack.enter_context(DebugContext())\n\u001b[32m    741\u001b[39m CompileEventLogger.pt2_compile(\n\u001b[32m    742\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minductor_compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    743\u001b[39m     is_backward=kwargs[\u001b[33m\"\u001b[39m\u001b[33mis_backward\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    744\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minductor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py:124\u001b[39m, in \u001b[36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m config.repro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     inner_compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.repro_after == \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:907\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **graph_kwargs)\u001b[39m\n\u001b[32m    905\u001b[39m TritonBundler.begin_compile()\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m     mb_compiled_graph = \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgraph_kwargs\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m mb_compiled_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    911\u001b[39m     mb_compiled_graph._time_taken_ns = time.time_ns() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1578\u001b[39m, in \u001b[36mfx_codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[39m\n\u001b[32m   1573\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scheme, _OutOfProcessFxCompile), (\n\u001b[32m   1574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masync is only valid with an out-of-process compile mode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1575\u001b[39m     )\n\u001b[32m   1576\u001b[39m     scheme = _AsyncFxCompile(scheme)\n\u001b[32m-> \u001b[39m\u001b[32m1578\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheme\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1456\u001b[39m, in \u001b[36m_InProcessFxCompile.codegen_and_compile\u001b[39m\u001b[34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[39m\n\u001b[32m   1438\u001b[39m         compiled_fn = AotCodeCompiler.compile(\n\u001b[32m   1439\u001b[39m             graph,\n\u001b[32m   1440\u001b[39m             wrapper_code.value,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1453\u001b[39m             ],\n\u001b[32m   1454\u001b[39m         )\n\u001b[32m   1455\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1456\u001b[39m     compiled_module = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1457\u001b[39m     compiled_fn = compiled_module.call\n\u001b[32m   1458\u001b[39m     compiled_fn_runner = \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   1459\u001b[39m         compiled_module, \u001b[33m\"\u001b[39m\u001b[33mrunner\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1460\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/graph.py:2293\u001b[39m, in \u001b[36mGraphLowering.compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> CompiledModule:\n\u001b[32m   2287\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   2288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraphLowering.compile_to_module\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2289\u001b[39m         phase_name=\u001b[33m\"\u001b[39m\u001b[33mcode_gen\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2290\u001b[39m         log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2291\u001b[39m         dynamo_compile_column_us=\u001b[33m\"\u001b[39m\u001b[33minductor_code_gen_cumulative_compile_time_us\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2292\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m2293\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/graph.py:2299\u001b[39m, in \u001b[36mGraphLowering._compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2295\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> CompiledModule:\n\u001b[32m   2296\u001b[39m     \u001b[38;5;66;03m# If we're here, we don't have to worry about the kernel code, which is only\u001b[39;00m\n\u001b[32m   2297\u001b[39m     \u001b[38;5;66;03m# returned separately in AOTInductor mode.\u001b[39;00m\n\u001b[32m   2298\u001b[39m     wrapper_code, _ = (\n\u001b[32m-> \u001b[39m\u001b[32m2299\u001b[39m         \u001b[38;5;28mself\u001b[39m.codegen_with_cpp_wrapper() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cpp_wrapper \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2300\u001b[39m     )\n\u001b[32m   2302\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(wrapper_code, ValueWithLineMap):\n\u001b[32m   2303\u001b[39m         mod = \u001b[38;5;28mself\u001b[39m._compile_to_module_lines(wrapper_code)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/graph.py:2234\u001b[39m, in \u001b[36mGraphLowering.codegen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2231\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mGraphLowering.codegen\u001b[39m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   2232\u001b[39m     \u001b[38;5;28mself\u001b[39m.init_wrapper_code()\n\u001b[32m-> \u001b[39m\u001b[32m2234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2235\u001b[39m     V.debug.draw_orig_fx_graph(\u001b[38;5;28mself\u001b[39m.orig_gm, \u001b[38;5;28mself\u001b[39m.scheduler.nodes)\n\u001b[32m   2237\u001b[39m     \u001b[38;5;28mself\u001b[39m.wrapper_code.push_codegened_graph(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/graph.py:2228\u001b[39m, in \u001b[36mGraphLowering._update_scheduler\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2225\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Scheduler\n\u001b[32m   2227\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config.patch(\u001b[33m\"\u001b[39m\u001b[33mtriton.store_cubin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2228\u001b[39m     \u001b[38;5;28mself\u001b[39m.scheduler = \u001b[43mScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/scheduler.py:2025\u001b[39m, in \u001b[36mScheduler.__init__\u001b[39m\u001b[34m(self, nodes)\u001b[39m\n\u001b[32m   2023\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: \u001b[38;5;28mlist\u001b[39m[ir.Operation]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2024\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mScheduler.__init__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2025\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/scheduler.py:2044\u001b[39m, in \u001b[36mScheduler._init\u001b[39m\u001b[34m(self, nodes)\u001b[39m\n\u001b[32m   2035\u001b[39m \u001b[38;5;28mself\u001b[39m.completed_operations: OrderedSet[\u001b[38;5;28mstr\u001b[39m] = OrderedSet()\n\u001b[32m   2036\u001b[39m \u001b[38;5;28mself\u001b[39m.available_buffer_names = OrderedSet(\n\u001b[32m   2037\u001b[39m     [\n\u001b[32m   2038\u001b[39m         *V.graph.graph_inputs.keys(),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2041\u001b[39m     ]\n\u001b[32m   2042\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2044\u001b[39m \u001b[38;5;28mself\u001b[39m.nodes = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_scheduler_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   2045\u001b[39m \u001b[38;5;28mself\u001b[39m.update_zero_dim_cpu_tensor()\n\u001b[32m   2046\u001b[39m \u001b[38;5;66;03m# some new constants could have been created above\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/scheduler.py:2044\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   2035\u001b[39m \u001b[38;5;28mself\u001b[39m.completed_operations: OrderedSet[\u001b[38;5;28mstr\u001b[39m] = OrderedSet()\n\u001b[32m   2036\u001b[39m \u001b[38;5;28mself\u001b[39m.available_buffer_names = OrderedSet(\n\u001b[32m   2037\u001b[39m     [\n\u001b[32m   2038\u001b[39m         *V.graph.graph_inputs.keys(),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2041\u001b[39m     ]\n\u001b[32m   2042\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2044\u001b[39m \u001b[38;5;28mself\u001b[39m.nodes = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_scheduler_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[32m   2045\u001b[39m \u001b[38;5;28mself\u001b[39m.update_zero_dim_cpu_tensor()\n\u001b[32m   2046\u001b[39m \u001b[38;5;66;03m# some new constants could have been created above\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/scheduler.py:2190\u001b[39m, in \u001b[36mScheduler.create_scheduler_node\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   2188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m NopKernelSchedulerNode(\u001b[38;5;28mself\u001b[39m, node)\n\u001b[32m   2189\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (ir.ComputedBuffer, ir.TemplateBuffer)):\n\u001b[32m-> \u001b[39m\u001b[32m2190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSchedulerNode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, ir.ExternKernel):\n\u001b[32m   2192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ExternKernelSchedulerNode(\u001b[38;5;28mself\u001b[39m, node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/scheduler.py:1014\u001b[39m, in \u001b[36mSchedulerNode.__init__\u001b[39m\u001b[34m(self, scheduler, node)\u001b[39m\n\u001b[32m   1012\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(scheduler)\n\u001b[32m   1013\u001b[39m \u001b[38;5;28mself\u001b[39m._init_from_node(node)\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_attrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/scheduler.py:1022\u001b[39m, in \u001b[36mSchedulerNode._compute_attrs\u001b[39m\u001b[34m(self, extra_indexing_constraints, recompute_sizes_body_func)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute_attrs\u001b[39m(\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1018\u001b[39m     extra_indexing_constraints: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[Any, Any], \u001b[38;5;28mlist\u001b[39m[Any]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1019\u001b[39m     recompute_sizes_body_func: Optional[Callable[..., Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1020\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.node, (ir.ComputedBuffer, ir.TemplateBuffer))\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     \u001b[38;5;28mself\u001b[39m._sizes, \u001b[38;5;28mself\u001b[39m._body = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimplify_and_reorder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_indexing_constraints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_indexing_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrecompute_sizes_body_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecompute_sizes_body_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m     device = \u001b[38;5;28mself\u001b[39m.node.get_device_or_error()\n\u001b[32m   1028\u001b[39m     group_fn = \u001b[38;5;28mself\u001b[39m.scheduler.get_backend(device).group_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:4385\u001b[39m, in \u001b[36mComputedBuffer.simplify_and_reorder\u001b[39m\u001b[34m(self, extra_indexing_constraints, recompute_sizes_body_func)\u001b[39m\n\u001b[32m   4359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimplify_and_reorder\u001b[39m(\n\u001b[32m   4360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4361\u001b[39m     extra_indexing_constraints: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[Any, Any], \u001b[38;5;28mlist\u001b[39m[Any]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   4362\u001b[39m     recompute_sizes_body_func: Optional[Callable[..., Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   4363\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[sympy.Expr], \u001b[38;5;28mlist\u001b[39m[sympy.Expr]], LoopBody]:\n\u001b[32m   4364\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4365\u001b[39m \u001b[33;03m    This is a main place where we do loop transformations in a\u001b[39;00m\n\u001b[32m   4366\u001b[39m \u001b[33;03m    backend-agnostic way.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4379\u001b[39m \u001b[33;03m    on the default body. This can be useful to append additional loop transformations.\u001b[39;00m\n\u001b[32m   4380\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4381\u001b[39m     (\n\u001b[32m   4382\u001b[39m         (index_size, reduce_size),\n\u001b[32m   4383\u001b[39m         body,\n\u001b[32m   4384\u001b[39m         (index_vars, reduce_vars),\n\u001b[32m-> \u001b[39m\u001b[32m4385\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_default_sizes_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4387\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m recompute_sizes_body_func:\n\u001b[32m   4388\u001b[39m         (\n\u001b[32m   4389\u001b[39m             (index_size, reduce_size),\n\u001b[32m   4390\u001b[39m             body,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4393\u001b[39m             (index_size, reduce_size), body, (index_vars, reduce_vars)\n\u001b[32m   4394\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:6\u001b[39m, in \u001b[36mget_default_sizes_body_cache_on_self\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:4338\u001b[39m, in \u001b[36mComputedBuffer.get_default_sizes_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   4334\u001b[39m args, var_ranges = dependencies.index_vars_squeeze(\n\u001b[32m   4335\u001b[39m     \u001b[38;5;28mself\u001b[39m.data.get_pointwise_size(), \u001b[38;5;28mself\u001b[39m.data.get_reduction_size(), prefix=\u001b[33m\"\u001b[39m\u001b[33mq\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4336\u001b[39m )\n\u001b[32m   4337\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m patch.object(ConstantBuffer, \u001b[33m\"\u001b[39m\u001b[33moverride_device\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.get_device()):\n\u001b[32m-> \u001b[39m\u001b[32m4338\u001b[39m     body = \u001b[43mLoopBody\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4339\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_store_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4340\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_reduction_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvar_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4342\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4343\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4344\u001b[39m index_vars = []\n\u001b[32m   4345\u001b[39m reduce_vars: \u001b[38;5;28mlist\u001b[39m[Any] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/loop_body.py:122\u001b[39m, in \u001b[36mLoopBody.__init__\u001b[39m\u001b[34m(self, fn, args, var_ranges, iter_vars, reduce_vars)\u001b[39m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_with_copy(fn, args)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_with_tracing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28mself\u001b[39m.indexing = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/loop_body.py:136\u001b[39m, in \u001b[36mLoopBody._init_with_tracing\u001b[39m\u001b[34m(self, fn, args)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mself\u001b[39m.memory_usage = {t: [] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m MemoryUsageType}\n\u001b[32m    135\u001b[39m \u001b[38;5;28mself\u001b[39m.op_counts = collections.Counter()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28mself\u001b[39m.root_block = \u001b[43mLoopBodyBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# traces\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.indexing_exprs_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/loop_body.py:487\u001b[39m, in \u001b[36mLoopBodyBlock.__init__\u001b[39m\u001b[34m(self, body, fn, args)\u001b[39m\n\u001b[32m    480\u001b[39m     handler = IndexPropagation(\n\u001b[32m    481\u001b[39m         handler, \u001b[38;5;28mself\u001b[39m.body.var_ranges, \u001b[38;5;28mself\u001b[39m.body.indirect_var_ranges\n\u001b[32m    482\u001b[39m     )\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m V.set_ops_handler(handler):\n\u001b[32m    485\u001b[39m     \u001b[38;5;66;03m# This indirection is just a cute way to get IndexPropagation to\u001b[39;00m\n\u001b[32m    486\u001b[39m     \u001b[38;5;66;03m# unwrap the return value.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     ops.output(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m.graph = tracer.graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:1005\u001b[39m, in \u001b[36mPointwise.store_output\u001b[39m\u001b[34m(self, output_name, indexer, vars)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore_output\u001b[39m(\n\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1000\u001b[39m     output_name: Optional[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   1001\u001b[39m     indexer: Callable[[Sequence[Expr]], Never],\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28mvars\u001b[39m: Sequence[Expr],\n\u001b[32m   1003\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1004\u001b[39m     loader = \u001b[38;5;28mself\u001b[39m.make_loader()\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ops.store(output_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33munnamed\u001b[39m\u001b[33m\"\u001b[39m, indexer(\u001b[38;5;28mvars\u001b[39m), \u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:2685\u001b[39m, in \u001b[36mBaseView.make_loader.<locals>.loader\u001b[39m\u001b[34m(idx)\u001b[39m\n\u001b[32m   2684\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloader\u001b[39m(idx: Sequence[Expr]) -> OpsValue:\n\u001b[32m-> \u001b[39m\u001b[32m2685\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/lowering.py:606\u001b[39m, in \u001b[36mmake_pointwise.<locals>.inner.<locals>.inner_fn\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    604\u001b[39m inputs_loaded = []\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inp_index, load \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loaders):\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     out = \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m     inp_dtype = inputs[inp_index].get_dtype()\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m emulate_precision_casts \u001b[38;5;129;01mand\u001b[39;00m inp_dtype \u001b[38;5;129;01min\u001b[39;00m low_pr_fp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:2685\u001b[39m, in \u001b[36mBaseView.make_loader.<locals>.loader\u001b[39m\u001b[34m(idx)\u001b[39m\n\u001b[32m   2684\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloader\u001b[39m(idx: Sequence[Expr]) -> OpsValue:\n\u001b[32m-> \u001b[39m\u001b[32m2685\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:1369\u001b[39m, in \u001b[36mReduction._unroll_reduction_fn.<locals>.fn\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn\u001b[39m(index: Sequence[_IntLike]) -> Any:\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcombine_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduction_ranges\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:1372\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn\u001b[39m(index: Sequence[_IntLike]) -> Any:\n\u001b[32m   1369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m functools.reduce(\n\u001b[32m   1370\u001b[39m         combine_fn,\n\u001b[32m   1371\u001b[39m         (\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m             \u001b[43mvalue_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m rindex \u001b[38;5;129;01min\u001b[39;00m itertools.product(\n\u001b[32m   1374\u001b[39m                 *[\u001b[38;5;28mrange\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m reduction_ranges]\n\u001b[32m   1375\u001b[39m             )\n\u001b[32m   1376\u001b[39m         ),\n\u001b[32m   1377\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/lowering.py:5804\u001b[39m, in \u001b[36m_make_reduction_inner.<locals>.loader\u001b[39m\u001b[34m(index, reduction_index)\u001b[39m\n\u001b[32m   5800\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, var \u001b[38;5;129;01min\u001b[39;00m itertools.chain(\n\u001b[32m   5801\u001b[39m     \u001b[38;5;28mzip\u001b[39m(kept_idx, index), \u001b[38;5;28mzip\u001b[39m(reduced_idx, reduction_index)\n\u001b[32m   5802\u001b[39m ):\n\u001b[32m   5803\u001b[39m     new_index[idx] = var\n\u001b[32m-> \u001b[39m\u001b[32m5804\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:2685\u001b[39m, in \u001b[36mBaseView.make_loader.<locals>.loader\u001b[39m\u001b[34m(idx)\u001b[39m\n\u001b[32m   2684\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloader\u001b[39m(idx: Sequence[Expr]) -> OpsValue:\n\u001b[32m-> \u001b[39m\u001b[32m2685\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/lowering.py:606\u001b[39m, in \u001b[36mmake_pointwise.<locals>.inner.<locals>.inner_fn\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    604\u001b[39m inputs_loaded = []\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inp_index, load \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loaders):\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     out = \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m     inp_dtype = inputs[inp_index].get_dtype()\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m emulate_precision_casts \u001b[38;5;129;01mand\u001b[39;00m inp_dtype \u001b[38;5;129;01min\u001b[39;00m low_pr_fp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/ir.py:4070\u001b[39m, in \u001b[36mBuffer.make_loader.<locals>.loader\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m   4068\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloader\u001b[39m(index):  \u001b[38;5;66;03m# type: ignore[no-untyped-def]\u001b[39;00m\n\u001b[32m   4069\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.make_indexer()\n\u001b[32m-> \u001b[39m\u001b[32m4070\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munnamed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:212\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(self, name, index)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/virtualized.py:310\u001b[39m, in \u001b[36mOpsWrapper._default\u001b[39m\u001b[34m(self, name, args, kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m new_args = [OpsWrapper._unwrap(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m    309\u001b[39m new_kwargs = {k: OpsWrapper._unwrap(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items()}\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m OpsWrapper._wrap(\u001b[38;5;28mgetattr\u001b[39m(_ops, name)(*new_args, **new_kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/virtualized.py:153\u001b[39m, in \u001b[36mVirtualized.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._get_handler(), name)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_llm.train(model, tokenizer, log_name=None, max_samples=256,\n",
    "                per_device_train_batch_size=1, gradient_accumulation_steps=16, num_train_epochs=5, eval_per_epoch=False, save=False, use_amp=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

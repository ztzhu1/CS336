{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-05 14:42:52 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "project_dir = Path(os.path.abspath('')).parent\n",
    "sys.path.insert(0, project_dir.as_posix())\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import  pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from cs336_alignment import  train_llm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = train_llm.load_model(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mztzhu1\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/assignment5-alignment/cs336_alignment/wandb/run-20251105_144319-8oqsgkzx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx' target=\"_blank\">MATH_100</a></strong> to <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fee3ba20fe4b1eb9148d22de36af7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2, 1/24], loss: 0.6364, token_entropy: 0.5592\n",
      "[1/2, 2/24], loss: 0.5823, token_entropy: 0.5860\n",
      "[1/2, 3/24], loss: 0.5400, token_entropy: 0.5778\n",
      "[1/2, 4/24], loss: 0.3649, token_entropy: 0.2796\n",
      "[1/2, 5/24], loss: 0.3937, token_entropy: 0.3809\n",
      "[1/2, 6/24], loss: 0.4303, token_entropy: 0.3602\n",
      "[1/2, 7/24], loss: 0.3572, token_entropy: 0.3301\n",
      "[1/2, 8/24], loss: 0.4178, token_entropy: 0.3572\n",
      "[1/2, 9/24], loss: 0.4333, token_entropy: 0.3701\n",
      "[1/2, 10/24], loss: 0.4496, token_entropy: 0.3969\n",
      "[1/2, 11/24], loss: 0.4327, token_entropy: 0.3465\n",
      "[1/2, 12/24], loss: 0.4501, token_entropy: 0.3917\n",
      "[2/2, 13/24], loss: 0.1490, token_entropy: 0.2787\n",
      "[2/2, 14/24], loss: 0.1464, token_entropy: 0.2636\n",
      "[2/2, 15/24], loss: 0.1467, token_entropy: 0.2303\n",
      "[2/2, 16/24], loss: 0.2039, token_entropy: 0.2734\n",
      "[2/2, 17/24], loss: 0.1493, token_entropy: 0.1984\n",
      "[2/2, 18/24], loss: 0.1607, token_entropy: 0.2045\n",
      "[2/2, 19/24], loss: 0.1483, token_entropy: 0.1847\n",
      "[2/2, 20/24], loss: 0.1164, token_entropy: 0.1467\n",
      "[2/2, 21/24], loss: 0.1352, token_entropy: 0.1438\n",
      "[2/2, 22/24], loss: 0.1760, token_entropy: 0.1820\n",
      "[2/2, 23/24], loss: 0.2035, token_entropy: 0.1781\n",
      "[2/2, 24/24], loss: 0.1164, token_entropy: 0.1729\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁████████████</td></tr><tr><td>train/loss</td><td>█▇▇▄▅▅▄▅▅▅▅▅▁▁▁▂▁▂▁▁▁▂▂▁</td></tr><tr><td>train/token_entropy</td><td>███▃▅▄▄▄▅▅▄▅▃▃▂▃▂▂▂▁▁▂▂▁</td></tr><tr><td>train_step</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_step</td><td>24</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MATH_100</strong> at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/8oqsgkzx</a><br> View project at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251105_144319-8oqsgkzx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_llm.train(model, tokenizer, log_name='MATH_100', per_device_train_batch_size=1, gradient_accumulation_steps=8, num_train_epochs=2, max_steps=25)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4c2825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "project_dir = Path(os.path.abspath('')).parent\n",
    "sys.path.insert(0, project_dir.as_posix())\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import wandb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from cs336_alignment import train_llm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44fad24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_step': 16, 'eval/epoch': 1, 'eval/reward': 0.43, 'eval/format_reward': 0.94, 'eval/answer_reward': 0.43, 'eval/num_tokens_problem': 51.34, 'eval/num_tokens_right_problem': 36.26, 'eval/num_tokens_wrong_problem': 62.72, 'eval/num_tokens_response': 353.36, 'eval/num_tokens_right_response': 289.88, 'eval/num_tokens_wrong_response': 401.25}\n",
      "{'eval_step': 32, 'eval/epoch': 2, 'eval/reward': 0.63, 'eval/format_reward': 0.97, 'eval/answer_reward': 0.63, 'eval/num_tokens_problem': 51.34, 'eval/num_tokens_right_problem': 46.0, 'eval/num_tokens_wrong_problem': 60.43, 'eval/num_tokens_response': 403.62, 'eval/num_tokens_right_response': 327.33, 'eval/num_tokens_wrong_response': 533.51}\n",
      "{'eval_step': 48, 'eval/epoch': 3, 'eval/reward': 0.66, 'eval/format_reward': 0.98, 'eval/answer_reward': 0.66, 'eval/num_tokens_problem': 51.34, 'eval/num_tokens_right_problem': 44.74, 'eval/num_tokens_wrong_problem': 64.15, 'eval/num_tokens_response': 354.28, 'eval/num_tokens_right_response': 299.92, 'eval/num_tokens_wrong_response': 459.79}\n",
      "{'eval_step': 64, 'eval/epoch': 4, 'eval/reward': 0.73, 'eval/format_reward': 0.98, 'eval/answer_reward': 0.73, 'eval/num_tokens_problem': 51.34, 'eval/num_tokens_right_problem': 48.3, 'eval/num_tokens_wrong_problem': 59.56, 'eval/num_tokens_response': 372.81, 'eval/num_tokens_right_response': 318.74, 'eval/num_tokens_wrong_response': 519.0}\n",
      "{'eval_step': 80, 'eval/epoch': 5, 'eval/reward': 0.77, 'eval/format_reward': 0.97, 'eval/answer_reward': 0.77, 'eval/num_tokens_problem': 51.34, 'eval/num_tokens_right_problem': 42.94, 'eval/num_tokens_wrong_problem': 79.48, 'eval/num_tokens_response': 375.44, 'eval/num_tokens_right_response': 328.82, 'eval/num_tokens_wrong_response': 531.52}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = train_llm.load_tokenizer()\n",
    "eval_path = project_dir / \"evaluation\"\n",
    "logs = []\n",
    "for epoch in range(5):\n",
    "    epoch += 1\n",
    "    step = epoch * 16\n",
    "    df = train_llm.load_jsonl(\n",
    "        eval_path / f\"Qwen2.5-Math-1.5B-MATH-sample256-epoch{epoch}-step{step}.jsonl\"\n",
    "    )\n",
    "    format_reward = df.format_reward.mean().item()\n",
    "    answer_reward = df.answer_reward.mean().item()\n",
    "    reward = df.reward.mean().item()\n",
    "    num_tokens_problem = []\n",
    "    num_tokens_right_problem = []\n",
    "    num_tokens_wrong_problem = []\n",
    "    num_tokens_response = []\n",
    "    num_tokens_right_response = []\n",
    "    num_tokens_wrong_response = []\n",
    "    for i in range(len(df)):\n",
    "        num_token_problem = len(tokenizer.encode(df.problem[i]))\n",
    "        num_token_response = len(tokenizer.encode(df.response[i]))\n",
    "        num_tokens_problem.append(num_token_problem)\n",
    "        num_tokens_response.append(num_token_response)\n",
    "        if df.reward[i] > 0:\n",
    "            num_tokens_right_problem.append(num_token_problem)\n",
    "            num_tokens_right_response.append(num_token_response)\n",
    "        else:\n",
    "            num_tokens_wrong_problem.append(num_token_problem)\n",
    "            num_tokens_wrong_response.append(num_token_response)\n",
    "    log = {\n",
    "        \"eval_step\": step,\n",
    "        \"eval/epoch\": epoch,\n",
    "        \"eval/reward\": reward,\n",
    "        \"eval/format_reward\": format_reward,\n",
    "        \"eval/answer_reward\": answer_reward,\n",
    "        \"eval/num_tokens_problem\": np.mean(num_tokens_problem).round(2).item(),\n",
    "        \"eval/num_tokens_right_problem\": np.mean(num_tokens_right_problem).round(2).item(),\n",
    "        \"eval/num_tokens_wrong_problem\": np.mean(num_tokens_wrong_problem).round(2).item(),\n",
    "        \"eval/num_tokens_response\": np.mean(num_tokens_response).round(2).item(),\n",
    "        \"eval/num_tokens_right_response\": np.mean(num_tokens_right_response).round(2).item(),\n",
    "        \"eval/num_tokens_wrong_response\": np.mean(num_tokens_wrong_response).round(2).item(),\n",
    "    }\n",
    "    logs.append(log)\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90ed01b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mztzhu1\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ztzhu/AI/CS336/assignment5-alignment/cs336_alignment/wandb/run-20251107_002318-uerwbrkf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf' target=\"_blank\">Qwen2.5-Math-1.5B-MATH</a></strong> to <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/answer_reward</td><td>▁▅▆▇█</td></tr><tr><td>eval/epoch</td><td>▁▃▅▆█</td></tr><tr><td>eval/format_reward</td><td>▁▆██▆</td></tr><tr><td>eval/num_tokens_problem</td><td>▁▁▁▁▁</td></tr><tr><td>eval/num_tokens_response</td><td>▁█▁▄▄</td></tr><tr><td>eval/num_tokens_right_problem</td><td>▁▇▆█▅</td></tr><tr><td>eval/num_tokens_right_response</td><td>▁█▃▆█</td></tr><tr><td>eval/num_tokens_wrong_problem</td><td>▂▁▃▁█</td></tr><tr><td>eval/num_tokens_wrong_response</td><td>▁█▄▇█</td></tr><tr><td>eval/reward</td><td>▁▅▆▇█</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/answer_reward</td><td>0.77</td></tr><tr><td>eval/epoch</td><td>5</td></tr><tr><td>eval/format_reward</td><td>0.97</td></tr><tr><td>eval/num_tokens_problem</td><td>51.34</td></tr><tr><td>eval/num_tokens_response</td><td>375.44</td></tr><tr><td>eval/num_tokens_right_problem</td><td>42.94</td></tr><tr><td>eval/num_tokens_right_response</td><td>328.82</td></tr><tr><td>eval/num_tokens_wrong_problem</td><td>79.48</td></tr><tr><td>eval/num_tokens_wrong_response</td><td>531.52</td></tr><tr><td>eval/reward</td><td>0.77</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Qwen2.5-Math-1.5B-MATH</strong> at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B/runs/uerwbrkf</a><br> View project at: <a href='https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B' target=\"_blank\">https://wandb.ai/ztzhu11/FT_Qwen2.5-Math-1.5B</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251107_002318-uerwbrkf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity=\"ztzhu11\",\n",
    "    project=\"FT_Qwen2.5-Math-1.5B\",\n",
    "    resume=\"must\",\n",
    "    id=\"uerwbrkf\",\n",
    ")\n",
    "for log in logs:\n",
    "    run.log(log)\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-05 15:09:59 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from unittest.mock import patch\n",
    "project_dir = Path(os.path.abspath('')).parent\n",
    "sys.path.insert(0, project_dir.as_posix())\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import  pyplot as plt\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoModelForCausalLM\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.model_executor import set_random_seed\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from cs336_alignment import  train_llm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-05 15:10:44 [utils.py:233] non-default args: {'gpu_memory_utilization': 0.8, 'disable_log_stats': True, 'model': '/workspace/assignment5-alignment/checkpoints/MATH_100_step24'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-05 15:10:44 [model.py:547] Resolved architecture: Qwen2ForCausalLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-05 15:10:44 [model.py:1730] Downcasting torch.float32 to torch.float16.\n",
      "INFO 11-05 15:10:44 [model.py:1510] Using max model len 4096\n",
      "INFO 11-05 15:10:46 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:10:47 [core.py:644] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:10:47 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/workspace/assignment5-alignment/checkpoints/MATH_100_step24', speculative_config=None, tokenizer='/workspace/assignment5-alignment/checkpoints/MATH_100_step24', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/workspace/assignment5-alignment/checkpoints/MATH_100_step24, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\",\"vllm.sparse_attn_indexer\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":[2,1],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"use_inductor_graph_partition\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m ERROR 11-05 15:10:50 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:10:50 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m WARNING 11-05 15:10:51 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:10:51 [gpu_model_runner.py:2602] Starting to load model /workspace/assignment5-alignment/checkpoints/MATH_100_step24...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:10:51 [gpu_model_runner.py:2634] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:10:51 [cuda.py:372] Using FlexAttention backend on V1 engine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126de21830b8477dafdc8ba6b17372c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:10:53 [default_loader.py:267] Loading weights took 1.58 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:10:54 [gpu_model_runner.py:2653] Model loading took 2.8798 GiB and 1.884412 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:01 [backends.py:548] Using cache directory: /root/.cache/vllm/torch_compile_cache/e10aa591c0/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:01 [backends.py:559] Dynamo bytecode transform time: 6.43 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:04 [backends.py:197] Cache the graph for dynamic shape for later use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m [rank0]:W1105 15:11:05.579000 10900 site-packages/torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:23 [backends.py:218] Compiling a graph for dynamic shape takes 22.23 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:30 [monitor.py:34] torch.compile takes 28.66 s in total\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:32 [gpu_worker.py:298] Available KV cache memory: 7.33 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:32 [kv_cache_utils.py:1087] GPU KV cache size: 274,400 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:32 [kv_cache_utils.py:1091] Maximum concurrency for 4,096 tokens per request: 66.99x\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m WARNING 11-05 15:11:32 [gpu_model_runner.py:3663] CUDAGraphMode.FULL_AND_PIECEWISE is not supported with FlexAttentionMetadataBuilder backend (support: AttentionCGSupport.NEVER); setting cudagraph_mode=PIECEWISE because attention is compiled piecewise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:03<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:37 [gpu_model_runner.py:3480] Graph capturing finished in 5 secs, took 0.40 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m INFO 11-05 15:11:37 [core.py:210] init engine (profile, create kv cache, warmup model) took 43.56 seconds\n",
      "INFO 11-05 15:11:38 [llm.py:306] Supported_tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model=project_dir.joinpath('checkpoints', 'MATH_100_step24').as_posix(),\n",
    "    gpu_memory_utilization=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many vertical asymptotes does the graph of...</td>\n",
       "      <td>Level 3</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>The denominator of the rational function facto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the positive difference between $120\\%...</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>One hundred twenty percent of 30 is $120\\cdot3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find $x$ such that $\\lceil x \\rceil + x = \\dfr...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>First, we note that $x$ must be positive, sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evaluate $i^5+i^{-25}+i^{45}$.</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>We have $i^5 = i^4\\cdot i = 1\\cdot (i) = i$.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If $2^8=4^x$, what is the value of $x$?</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>Rewrite $4$ as $2^2$ to find $4^x=2^{2x}$.  Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An infinite geometric series has sum 2000.  A ...</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>Let $a$ be the first term and $r$ the ratio of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Twelve people purchased supplies for a ten-day...</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>Since each person of the original group had 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>How many integers belong to the arithmetic seq...</td>\n",
       "      <td>Level 3</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>The common difference is $20 - 13 = 7$.  If th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Of the four points $(2,2)$, $(9,11)$, $(5,7)$,...</td>\n",
       "      <td>Level 3</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>Consider points $P$, $Q$, and $R$. If the slop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Given the functions $f(x)=\\dfrac{x+5}{3}$ and ...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>We begin by calculating the inverse function $...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              problem    level     type  \\\n",
       "0   How many vertical asymptotes does the graph of...  Level 3  Algebra   \n",
       "1   What is the positive difference between $120\\%...  Level 1  Algebra   \n",
       "2   Find $x$ such that $\\lceil x \\rceil + x = \\dfr...  Level 4  Algebra   \n",
       "3                      Evaluate $i^5+i^{-25}+i^{45}$.  Level 5  Algebra   \n",
       "4             If $2^8=4^x$, what is the value of $x$?  Level 1  Algebra   \n",
       "..                                                ...      ...      ...   \n",
       "95  An infinite geometric series has sum 2000.  A ...  Level 5  Algebra   \n",
       "96  Twelve people purchased supplies for a ten-day...  Level 2  Algebra   \n",
       "97  How many integers belong to the arithmetic seq...  Level 3  Algebra   \n",
       "98  Of the four points $(2,2)$, $(9,11)$, $(5,7)$,...  Level 3  Algebra   \n",
       "99  Given the functions $f(x)=\\dfrac{x+5}{3}$ and ...  Level 4  Algebra   \n",
       "\n",
       "                                             solution  \n",
       "0   The denominator of the rational function facto...  \n",
       "1   One hundred twenty percent of 30 is $120\\cdot3...  \n",
       "2   First, we note that $x$ must be positive, sinc...  \n",
       "3   We have $i^5 = i^4\\cdot i = 1\\cdot (i) = i$.  ...  \n",
       "4   Rewrite $4$ as $2^2$ to find $4^x=2^{2x}$.  Si...  \n",
       "..                                                ...  \n",
       "95  Let $a$ be the first term and $r$ the ratio of...  \n",
       "96  Since each person of the original group had 10...  \n",
       "97  The common difference is $20 - 13 = 7$.  If th...  \n",
       "98  Consider points $P$, $Q$, and $R$. If the slop...  \n",
       "99  We begin by calculating the inverse function $...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    min_tokens=4,\n",
    "    max_tokens=1024,\n",
    "    stop=[\"</answer>\"],\n",
    "    include_stop_str_in_output=True,\n",
    ")\n",
    "path = project_dir.joinpath(\"data\", \"MATH\", \"validation.jsonl\")\n",
    "validation_data = pd.read_json(\n",
    "    path_or_buf=path,\n",
    "    lines=True\n",
    ")\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff54086ad20048bd852145b3a21b535e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bee0da3f4694904b161d0b150943384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=10900)\u001b[0;0m CUDAGraph supports dynamic shapes by recording a new graph for each distinct input size. Recording too many CUDAGraphs may lead to extra overhead. We have observed 51 distinct sizes. Please consider the following options for better performance: a) padding inputs to a few fixed number of shapes; or b) set torch._inductor.config.triton.cudagraph_skip_dynamic_graphs=True. Set torch._inductor.config.triton.cudagraph_dynamic_shape_warn_limit=None to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "train_llm.evaluate_vllm(llm=llm,\n",
    "    reward_fn=train_llm.drgrpo_grader.r1_zero_reward_fn,\n",
    "    prompts=list(validation_data.problem),\n",
    "    ground_truths=list(validation_data.solution),\n",
    "    sampling_params=sampling_params,\n",
    "    save_path=project_dir / \"evaluation\" / \"MATH_100_step24.jsonl\",\n",
    "    overwrite=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
